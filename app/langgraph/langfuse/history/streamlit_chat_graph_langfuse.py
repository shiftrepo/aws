import os
import uuid
import logging
import streamlit as st
import boto3
import tenacity

# LlamaIndex Core imports
from llama_index.core import PropertyGraphIndex, Settings # ChatPromptTemplate ã¯æœªä½¿ç”¨ãªã®ã§å‰Šé™¤ã‚‚å¯
from llama_index.core.memory import ChatMemoryBuffer
from llama_index.core.chat_engine import ContextChatEngine
from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore
from llama_index.llms.bedrock_converse import BedrockConverse
from llama_index.embeddings.bedrock import BedrockEmbedding

# --- Langfuseé–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’å¤‰æ›´ ---
# from langfuse.callback import CallbackHandler # å¤ã„ãƒãƒ³ãƒ‰ãƒ©ã‚’å‰Šé™¤
from llama_index.core.callbacks import CallbackManager # CallbackManagerã‚’è¿½åŠ 
from langfuse.llama_index import LlamaIndexCallbackHandler # LlamaIndexCallbackHandlerã‚’è¿½åŠ 

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ğŸŒ Langfuse session init (ã“ã‚Œã¯ Streamlit ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ç”¨ãªã®ã§æ®‹ã™)
if "session_id" not in st.session_state:
    st.session_state["session_id"] = str(uuid.uuid4())[:8]
session_id = st.session_state["session_id"]
logger.info(f"Streamlit Session ID: {session_id}") # ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ˜ç¢ºåŒ–

# --- Langfuse LlamaIndex Callback Handler ã®åˆæœŸåŒ–ã¨ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®š ---
logger.info("Initializing Langfuse LlamaIndex callback handler...")
# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ Langfuse ã®è¨­å®šã‚’èª­ã¿è¾¼ã‚€
langfuse_public_key = os.getenv("LANGFUSE_PUBLIC_KEY")
langfuse_secret_key = os.getenv("LANGFUSE_SECRET_KEY")
langfuse_host = os.getenv("LANGFUSE_HOST")

from langfuse.llama_index import LlamaIndexInstrumentor

# LlamaIndexã®æ“ä½œã‚’ãƒˆãƒ¬ãƒ¼ã‚¹ã™ã‚‹ãŸã‚ã«LlamaIndexInstrumentorã‚’åˆæœŸåŒ–
instrumentor = LlamaIndexInstrumentor(
    secret_key=os.environ.get("LANGFUSE_SECRET_KEY"),
    public_key=os.environ.get("LANGFUSE_PUBLIC_KEY"),
    host=os.environ.get("LANGFUSE_HOST")
)

if not (langfuse_public_key and langfuse_secret_key and langfuse_host):
    logger.warning("Langfuse environment variables (LANGFUSE_PUBLIC_KEY, LANGFUSE_SECRET_KEY, LANGFUSE_HOST) are not fully set. Langfuse callback handler will not be initialized.")
    # ãƒãƒ³ãƒ‰ãƒ©ãŒåˆæœŸåŒ–ã§ããªã„å ´åˆã¯ã€Settings.callback_manager ã‚’è¨­å®šã—ãªã„
    # ã‚‚ã—ãã¯ã‚¨ãƒ©ãƒ¼ã«ã™ã‚‹ãªã©ã€å¿…è¦ã«å¿œã˜ã¦å‡¦ç†ã‚’å¤‰æ›´ã—ã¦ãã ã•ã„
else:
    try:
        langfuse_callback_handler = LlamaIndexCallbackHandler(
            public_key=langfuse_public_key,
            secret_key=langfuse_secret_key,
            host=langfuse_host,
            # session_id ã¯ LlamaIndexCallbackHandler ã®åˆæœŸåŒ–å¼•æ•°ã«ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
            # Langfuse ã¯ãƒˆãƒ¬ãƒ¼ã‚¹ã”ã¨ã«ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ç®¡ç†ã—ã¾ã™ã€‚
            # å¿…è¦ã§ã‚ã‚Œã°ã€ãƒˆãƒ¬ãƒ¼ã‚¹ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚„ã‚¿ã‚°ã§ Streamlit ã® session_id ã‚’æ¸¡ã™ã“ã¨ã‚’æ¤œè¨ã—ã¾ã™ã€‚
            # ä¾‹: tags=["streamlit", f"session:{session_id}"]
            tags=["streamlit-app", "neo4j-rag", f"st_session:{session_id}"] # ã‚¿ã‚°ã« session_id ã‚’å«ã‚ã‚‹ä¾‹
        )
        logger.info("Setting global callback manager with Langfuse handler...")
        Settings.callback_manager = CallbackManager([langfuse_callback_handler])
        langfuse_callback_handler.set_trace_params(
                session_id = session_id
                )
    except Exception as e:
        logger.error(f"Failed to initialize Langfuse callback handler: {e}")
        # Langfuseã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¦ã‚‚ã‚¢ãƒ—ãƒªã®å®Ÿè¡Œã‚’ç¶šã‘ã‚‹å ´åˆãŒã‚ã‚‹ãŸã‚ã€
        # Settings.callback_manager ã¯è¨­å®šã•ã‚Œãªã„ã¾ã¾é€²ã‚€ã€‚

# Bedrock clients
logger.info("Creating boto3 session and bedrock client...")
# ç’°å¢ƒå¤‰æ•°ã®ãƒã‚§ãƒƒã‚¯ã‚’è¿½åŠ  (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID')
aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY')
aws_region = os.getenv('AWS_DEFAULT_REGION')

if not (aws_access_key_id and aws_secret_access_key and aws_region):
    st.error("AWS credentials or region not found in environment variables!")
    st.stop() # å¿…é ˆæƒ…å ±ãŒãªã„å ´åˆã¯ã‚¢ãƒ—ãƒªã‚’åœæ­¢

boto3_session = boto3.Session(
    aws_access_key_id=aws_access_key_id,
    aws_secret_access_key=aws_secret_access_key,
    region_name=aws_region
)
bedrock_client = boto3_session.client('bedrock-runtime')

# LLM
logger.info("Initializing Bedrock LLM...")
llm = BedrockConverse(
    model="anthropic.claude-3-haiku-20240307-v1:0",
    client=bedrock_client,
    # callbacks=[langfuse_handler] # Settings.callback_manager ã§ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«è¨­å®šã™ã‚‹ãŸã‚ä¸è¦
)

# Embedding
@tenacity.retry(stop=tenacity.stop_after_attempt(3),
                 wait=tenacity.wait_fixed(5),
                 retry=tenacity.retry_if_exception_type(Exception),
                 before_sleep=tenacity.before_sleep_log(logging, logging.WARNING))
def create_embedding_with_retry(client, model_name, request_timeout):
    logger.info("Creating Bedrock embedding model with retry...")
    # BedrockEmbedding ã‚‚ Settings.callback_manager ã‚’å‚ç…§ã™ã‚‹
    return BedrockEmbedding(
        model_name=model_name,
        client=client,
        use_async=False, # åŒæœŸå‡¦ç†ã®ã¾ã¾
        request_timeout=request_timeout
    )

embedding = create_embedding_with_retry(
    bedrock_client,
    "amazon.titan-embed-text-v2:0",
    request_timeout=60
)

# Set global settings (Callback Manager ã¯ä¸Šã§è¨­å®šæ¸ˆã¿)
logger.info("Setting global LLM and embedding settings...")
Settings.llm = llm
Settings.embed_model = embedding
# Settings.callback_manager ã¯ langfuse_callback_handler ã®åˆæœŸåŒ–å¾Œã«è¨­å®šæ¸ˆã¿

# Neo4j store
logger.info("Initializing Neo4j property graph store...")
# Neo4j ã®æ¥ç¶šæƒ…å ±ã‚‚ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã™ã‚‹ã®ãŒæœ›ã¾ã—ã„
neo4j_username = os.getenv("NEO4J_USERNAME", "neo4j")
neo4j_password = os.getenv("NEO4J_PASSWORD", "password")
neo4j_url = os.getenv("NEO4J_URL", "bolt://neo4jRAG:7687") # ç’°å¢ƒå¤‰æ•°ãŒãªã„å ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤

graph_store = Neo4jPropertyGraphStore(
    username=neo4j_username,
    password=neo4j_password,
    url=neo4j_url,
)

# Index
logger.info("Loading existing PropertyGraphIndex...")
try:
    index = PropertyGraphIndex.from_existing(
        # embed_model ã‚„ llm ã¯ Settings ã‹ã‚‰å–å¾—ã•ã‚Œã‚‹
        property_graph_store=graph_store,
        show_progress=True,
        # callback_manager ã‚‚ Settings ã‹ã‚‰å–å¾—ã•ã‚Œã‚‹
    )
except Exception as e:
    logger.error(f"Failed to load PropertyGraphIndex from Neo4j: {e}")
    st.error(f"æ—¢å­˜ã®ã‚°ãƒ©ãƒ•ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    st.stop() # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒãªã„ã¨å‹•ä½œã—ãªã„ãŸã‚åœæ­¢

# Retriever + Chat engine
if "chat_engine" not in st.session_state:
    logger.info("Creating chat engine with retriever and memory...")
    retriever = index.as_retriever(include_text=False) # include_text=False ã¯æ„å›³é€šã‚Šã‹ç¢ºèª
    memory = ChatMemoryBuffer.from_defaults(token_limit=3000)

    # ContextChatEngine.from_defaults ã¯ Settings ã‚’å‚ç…§ã™ã‚‹
    chat_engine = ContextChatEngine.from_defaults(
        retriever=retriever,
        memory=memory,
        # llm, callback_manager ã¯ Settings ã‹ã‚‰è‡ªå‹•çš„ã«é©ç”¨ã•ã‚Œã‚‹
        # verbose=True # ãƒ‡ãƒãƒƒã‚°ç”¨ã«è©³ç´°ãƒ­ã‚°ãŒå¿…è¦ãªå ´åˆ
    )
    st.session_state["chat_engine"] = chat_engine

chat_engine = st.session_state["chat_engine"]

# Streamlit UI
st.title("Neo4j + Claude Haiku ãƒãƒ£ãƒƒãƒˆ") # ãƒ¢ãƒ‡ãƒ«åã‚’åˆã‚ã›ã‚‹ (Haiku)

# Display chat history
if "chat_history" not in st.session_state:
    st.session_state["chat_history"] = []

for role, content in st.session_state["chat_history"]:
    with st.chat_message(role):
        st.markdown(content)

# Input
if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"):
    # è‡ªå‹•ãƒˆãƒ¬ãƒ¼ã‚¹ã‚’é–‹å§‹
    #instrumentor.start()
    logger.info(f"User input received: {prompt}")
    st.session_state["chat_history"].append(("user", prompt))
    with st.chat_message("user"):
        st.markdown(prompt)

    # langfuse_handler.flush() # LlamaIndexCallbackHandler ã§ã¯é€šå¸¸ä¸è¦

    with st.chat_message("assistant"):
        with st.spinner("è€ƒãˆä¸­..."): # å¿œç­”å¾…æ©Ÿä¸­ã«ã‚¹ãƒ”ãƒŠãƒ¼ã‚’è¡¨ç¤º
            logger.info("Generating response from chat engine...")
            try:
                # Chat Engine ã®å‘¼ã³å‡ºã—æ™‚ã«ãƒˆãƒ¬ãƒ¼ã‚¹æƒ…å ±ãŒä»˜ä¸ã•ã‚Œã‚‹ (SettingsçµŒç”±)
                response = chat_engine.chat(prompt)
                response_text = response.response
                logger.info(f"Response generated: {response_text}")
                st.markdown(response_text)
                st.session_state["chat_history"].append(("assistant", response_text))
                instrumentor.flush()

            except Exception as e:
                logger.error(f"Error during chat engine execution: {e}", exc_info=True)
                st.error(f"å¿œç­”ã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã‚‚å±¥æ­´ã«è¿½åŠ ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
                st.session_state["chat_history"].append(("assistant", f"ã‚¨ãƒ©ãƒ¼: {e}"))


# --- ã‚¢ãƒ—ãƒªçµ‚äº†æ™‚ã®å‡¦ç† ---
# Streamlit ã§ã¯æ˜ç¤ºçš„ãªçµ‚äº†ãƒ•ãƒƒã‚¯ã¯æ¨™æº–ã§ã¯ãªã„ãŒã€
# Langfuse ãƒãƒ³ãƒ‰ãƒ©ã®ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãŒå¿…è¦ãªå ´åˆ (é€šå¸¸ LlamaIndexCallbackHandler ã§ã¯ä¸è¦) ã¯
# try...finally ãƒ–ãƒ­ãƒƒã‚¯ãªã©ã‚’æ¤œè¨ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚
# logger.info("Shutting down Langfuse handler (if necessary)...")
# if 'langfuse_callback_handler' in locals() and hasattr(langfuse_callback_handler, 'shutdown'):
#      langfuse_callback_handler.shutdown()


