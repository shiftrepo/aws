#!/usr/bin/env python3
"""
Neo4j RAG MCP Server for Claude Code
Provides GraphRAG query capabilities through MCP protocol
"""

import json
import sys
import asyncio
from typing import Dict, Any, List
import logging
import time

# Add app path for imports
sys.path.append('/root/aws.git/container/graphRAG/app')

try:
    # MCP imports
    from mcp.server import Server
    from mcp.server.stdio import stdio_server
    from mcp import types
    
    # GraphRAG imports
    from neo4j import GraphDatabase
    import boto3
    from langchain_aws import ChatBedrock
    
    MCP_AVAILABLE = True
except ImportError as e:
    MCP_AVAILABLE = False
    print(f"MCP or dependencies not available: {e}")

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class Neo4jRAGMCPServer:
    """MCP Server for Neo4j RAG operations."""
    
    def __init__(self):
        self.app_name = "neo4j-rag"
        self.neo4j_uri = "bolt://neo4jRAG:7687"
        self.neo4j_user = "neo4j"
        self.neo4j_password = "password"
        self.region = "us-east-1"
        self.inference_profile_arn = "arn:aws:bedrock:us-east-1:711387140677:inference-profile/us.anthropic.claude-3-5-sonnet-20241022-v2:0"
        
        if MCP_AVAILABLE:
            self.server = Server(self.app_name)
            self.setup_handlers()
        else:
            logger.error("MCP not available, running in standalone mode")
    
    def setup_handlers(self):
        """Setup MCP handlers."""
        
        @self.server.list_tools()
        async def list_tools() -> List[types.Tool]:
            """List available tools."""
            return [
                types.Tool(
                    name="neo4j_rag_query",
                    description="Query Neo4j RAG database for information about characters, stories, etc.",
                    inputSchema={
                        "type": "object",
                        "properties": {
                            "question": {
                                "type": "string",
                                "description": "The question to ask the RAG system (e.g., '„É©„Ç™„Ç¶„ÅÆÂÖÑÂºü„ÅØË™∞„Åß„Åô„ÅãÔºü')"
                            }
                        },
                        "required": ["question"]
                    }
                ),
                types.Tool(
                    name="neo4j_rag_health",
                    description="Check Neo4j RAG system health status",
                    inputSchema={
                        "type": "object",
                        "properties": {}
                    }
                ),
                types.Tool(
                    name="neo4j_rag_stats", 
                    description="Get Neo4j RAG database statistics and information",
                    inputSchema={
                        "type": "object",
                        "properties": {}
                    }
                )
            ]
        
        @self.server.call_tool()
        async def call_tool(name: str, arguments: Dict[str, Any]) -> List[types.TextContent]:
            """Handle tool calls."""
            
            try:
                if name == "neo4j_rag_query":
                    return await self.handle_rag_query(arguments)
                elif name == "neo4j_rag_health":
                    return await self.handle_health_check()
                elif name == "neo4j_rag_stats":
                    return await self.handle_stats()
                else:
                    raise ValueError(f"Unknown tool: {name}")
            except Exception as e:
                logger.error(f"Tool call error: {e}")
                return [types.TextContent(
                    type="text",
                    text=f"‚ùå „Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü: {str(e)}"
                )]
    
    async def handle_rag_query(self, arguments: Dict[str, Any]) -> List[types.TextContent]:
        """Handle RAG query requests."""
        question = arguments.get("question", "")
        
        if not question.strip():
            return [types.TextContent(
                type="text",
                text="‚ùå Ë≥™Âïè„ÅåÁ©∫„Åß„Åô„ÄÇË≥™Âïè„ÇíÂÖ•Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
            )]
        
        try:
            logger.info(f"Processing RAG query: {question}")
            
            # Connect to Neo4j and search for relevant chunks
            driver = GraphDatabase.driver(
                self.neo4j_uri,
                auth=(self.neo4j_user, self.neo4j_password)
            )
            
            with driver.session() as session:
                # Search for relevant chunks containing the question keywords
                keywords = question.split()
                search_conditions = []
                params = {}
                
                # Build search query for better matching
                for i, keyword in enumerate(keywords[:3]):  # Limit to first 3 keywords
                    if len(keyword) > 1:  # Skip very short words
                        search_conditions.append(f"n.text CONTAINS $keyword{i}")
                        params[f"keyword{i}"] = keyword
                
                if not search_conditions:
                    # Fallback search if no good keywords
                    search_conditions = ["n.text IS NOT NULL AND n.text <> ''"]
                
                search_query = f"""
                    MATCH (n:Chunk) 
                    WHERE n.text IS NOT NULL AND n.text <> ''
                    AND ({' OR '.join(search_conditions)})
                    RETURN n.text as text, n.id as id
                    ORDER BY size(n.text) DESC
                    LIMIT 4
                """
                
                result = session.run(search_query, params)
                chunks = list(result)
                
                if not chunks:
                    # Try broader search if no specific matches
                    broader_result = session.run("""
                        MATCH (n:Chunk) 
                        WHERE n.text IS NOT NULL AND n.text <> ''
                        RETURN n.text as text, n.id as id
                        ORDER BY size(n.text) DESC
                        LIMIT 3
                    """)
                    chunks = list(broader_result)
                
                if not chunks:
                    return [types.TextContent(
                        type="text",
                        text="‚ùå „Éá„Éº„Çø„Éô„Éº„Çπ„Å´Èñ¢ÈÄ£„Åô„ÇãÊÉÖÂ†±„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ"
                    )]
                
                # Collect context
                context_texts = [record["text"] for record in chunks]
                full_context = "\n\n".join(context_texts)
                
            driver.close()
            
            # Generate answer using LLM
            bedrock_runtime = boto3.client("bedrock-runtime", region_name=self.region)
            llm = ChatBedrock(
                client=bedrock_runtime,
                model_id=self.inference_profile_arn,
                provider="anthropic",
                region_name=self.region,
                model_kwargs={"temperature": 0.0, "max_tokens": 1500}
            )
            
            prompt = f"""‰ª•‰∏ã„ÅÆÊñáËÑàÊÉÖÂ†±„Å´Âü∫„Å•„ÅÑ„Å¶„ÄÅË≥™Âïè„Å´Ê≠£Á¢∫„ÅßË©≥Á¥∞„Å´Á≠î„Åà„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
ÊñáËÑà„Å´Âê´„Åæ„Çå„ÇãÊÉÖÂ†±„ÅÆ„Åø„Çí‰ΩøÁî®„Åó„Å¶ÂõûÁ≠î„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

ÊñáËÑàÊÉÖÂ†±:
{full_context}

Ë≥™Âïè: {question}

ÂõûÁ≠î:"""
            
            logger.info("Generating LLM response...")
            response = llm.invoke(prompt)
            
            # Format response
            answer_text = f"""üîç **Ë≥™Âïè**: {question}

üìù **ÂõûÁ≠î**:
{response.content}

üìä **„Éá„Éº„Çø„ÇΩ„Éº„Çπ**: {len(chunks)}ÂÄã„ÅÆ„ÉÅ„É£„É≥„ÇØ„Åã„ÇâÊÉÖÂ†±„ÇíÂèñÂæó
‚è±Ô∏è **Âá¶ÁêÜÊôÇÈñì**: {time.strftime('%Y-%m-%d %H:%M:%S')}"""
            
            logger.info("RAG query completed successfully")
            
            return [types.TextContent(
                type="text", 
                text=answer_text
            )]
            
        except Exception as e:
            logger.error(f"RAG query error: {e}")
            return [types.TextContent(
                type="text",
                text=f"‚ùå „ÇØ„Ç®„É™Âá¶ÁêÜ‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü: {str(e)}"
            )]
    
    async def handle_health_check(self) -> List[types.TextContent]:
        """Handle health check requests."""
        try:
            logger.info("Performing health check...")
            
            # Test Neo4j connection
            driver = GraphDatabase.driver(
                self.neo4j_uri,
                auth=(self.neo4j_user, self.neo4j_password)
            )
            
            with driver.session() as session:
                # Basic connectivity test
                result = session.run("RETURN 1 as test")
                result.single()
                
                # Get chunk statistics
                chunk_result = session.run("""
                    MATCH (n:Chunk) 
                    WHERE n.text IS NOT NULL AND n.text <> '' 
                    RETURN count(n) as valid_chunks
                """)
                valid_chunks = chunk_result.single()["valid_chunks"]
                
                # Get total chunks
                total_result = session.run("MATCH (n:Chunk) RETURN count(n) as total")
                total_chunks = total_result.single()["total"]
            
            driver.close()
            
            # Test AWS Bedrock connection
            try:
                bedrock_runtime = boto3.client("bedrock-runtime", region_name=self.region)
                # Simple test call
                aws_status = "‚úÖ Available"
            except Exception as e:
                aws_status = f"‚ö†Ô∏è Warning: {str(e)}"
            
            health_info = f"""üè• **Neo4j RAG Health Check**

**„Éá„Éº„Çø„Éô„Éº„Çπ**: ‚úÖ Êé•Á∂öÊ≠£Â∏∏
**AWS Bedrock**: {aws_status}
**„Éá„Éº„ÇøÁµ±Ë®à**:
  - Á∑è„ÉÅ„É£„É≥„ÇØÊï∞: {total_chunks}
  - ÊúâÂäπ„ÉÅ„É£„É≥„ÇØÊï∞: {valid_chunks}
  - „Éá„Éº„Çø„Éô„Éº„ÇπURI: {self.neo4j_uri}
  - AWS„É™„Éº„Ç∏„Éß„É≥: {self.region}

**„Çπ„ÉÜ„Éº„Çø„Çπ**: ‚úÖ „Ç∑„Çπ„ÉÜ„É†Ê≠£Â∏∏
**„ÉÅ„Çß„ÉÉ„ÇØÊôÇÂàª**: {time.strftime('%Y-%m-%d %H:%M:%S')}"""
            
            logger.info("Health check completed successfully")
            
            return [types.TextContent(
                type="text",
                text=health_info
            )]
            
        except Exception as e:
            logger.error(f"Health check error: {e}")
            return [types.TextContent(
                type="text",
                text=f"‚ùå **Health Check Failed**: {str(e)}\n\n‚è±Ô∏è **ÊôÇÂàª**: {time.strftime('%Y-%m-%d %H:%M:%S')}"
            )]
    
    async def handle_stats(self) -> List[types.TextContent]:
        """Handle statistics requests."""
        try:
            logger.info("Gathering database statistics...")
            
            driver = GraphDatabase.driver(
                self.neo4j_uri,
                auth=(self.neo4j_user, self.neo4j_password)
            )
            
            with driver.session() as session:
                # Get comprehensive statistics
                queries = {
                    "total_nodes": "MATCH (n) RETURN count(n) as count",
                    "chunk_nodes": "MATCH (n:Chunk) RETURN count(n) as count", 
                    "valid_chunks": "MATCH (n:Chunk) WHERE n.text IS NOT NULL AND n.text <> '' RETURN count(n) as count",
                    "entity_nodes": "MATCH (n:entity) RETURN count(n) as count",
                    "empty_chunks": "MATCH (n:Chunk) WHERE n.text IS NULL OR n.text = '' RETURN count(n) as count"
                }
                
                stats = {}
                for key, query in queries.items():
                    result = session.run(query)
                    stats[key] = result.single()["count"]
                
                # Get sample of text lengths
                text_lengths = session.run("""
                    MATCH (n:Chunk) 
                    WHERE n.text IS NOT NULL AND n.text <> ''
                    RETURN size(n.text) as length
                    ORDER BY length DESC
                    LIMIT 5
                """)
                lengths = [record["length"] for record in text_lengths]
                
            driver.close()
            
            # Calculate percentages
            chunk_fill_rate = (stats["valid_chunks"] / stats["chunk_nodes"] * 100) if stats["chunk_nodes"] > 0 else 0
            
            stats_info = f"""üìä **Neo4j RAG Database Statistics**

**„Éé„Éº„ÉâÁµ±Ë®à**:
  - Á∑è„Éé„Éº„ÉâÊï∞: {stats["total_nodes"]:,}
  - Chunk„Éé„Éº„Éâ: {stats["chunk_nodes"]:,}
  - ÊúâÂäπ„ÉÜ„Ç≠„Çπ„ÉàChunk: {stats["valid_chunks"]:,}
  - Á©∫„ÅÆChunk: {stats["empty_chunks"]:,}
  - Entity„Éé„Éº„Éâ: {stats["entity_nodes"]:,}

**„Éá„Éº„ÇøÂìÅË≥™**:
  - ChunkÂÖÖÂ°´Áéá: {chunk_fill_rate:.1f}%
  - ÊúÄÂ§ß„ÉÜ„Ç≠„Çπ„ÉàÈï∑: {max(lengths) if lengths else 0:,} ÊñáÂ≠ó
  - Âπ≥Âùá„ÉÜ„Ç≠„Çπ„ÉàÈï∑: {sum(lengths)//len(lengths) if lengths else 0:,} ÊñáÂ≠ó

**Êé•Á∂öÊÉÖÂ†±**:
  - „Éá„Éº„Çø„Éô„Éº„ÇπURI: {self.neo4j_uri}
  - AWS„É™„Éº„Ç∏„Éß„É≥: {self.region}
  - LLM„É¢„Éá„É´: Claude 3.5 Sonnet

**ÁîüÊàêÊôÇÂàª**: {time.strftime('%Y-%m-%d %H:%M:%S')}"""
            
            logger.info("Statistics gathered successfully")
            
            return [types.TextContent(
                type="text",
                text=stats_info
            )]
            
        except Exception as e:
            logger.error(f"Stats error: {e}")
            return [types.TextContent(
                type="text",
                text=f"‚ùå **Áµ±Ë®àÂèñÂæó„Ç®„É©„Éº**: {str(e)}\n\n‚è±Ô∏è **ÊôÇÂàª**: {time.strftime('%Y-%m-%d %H:%M:%S')}"
            )]
    
    async def run(self):
        """Run the MCP server."""
        if not MCP_AVAILABLE:
            logger.error("Cannot run MCP server - dependencies not available")
            return
            
        logger.info(f"Starting {self.app_name} MCP Server...")
        
        async with stdio_server() as (read_stream, write_stream):
            await self.server.run(
                read_stream,
                write_stream,
                self.server.create_initialization_options()
            )

def standalone_test():
    """Standalone test mode when MCP is not available."""
    print("üß™ Neo4j RAG Standalone Test Mode")
    print("=" * 50)
    
    server = Neo4jRAGMCPServer()
    
    # Test health check
    print("\n1. Health Check Test:")
    try:
        driver = GraphDatabase.driver(
            server.neo4j_uri,
            auth=(server.neo4j_user, server.neo4j_password)
        )
        with driver.session() as session:
            result = session.run("RETURN 1 as test")
            result.single()
        driver.close()
        print("‚úÖ Neo4j connection successful")
    except Exception as e:
        print(f"‚ùå Neo4j connection failed: {e}")
    
    # Test query
    print("\n2. Sample Query Test:")
    question = "„É©„Ç™„Ç¶„ÅÆÂÖÑÂºü„ÅØ"
    print(f"Question: {question}")
    
    try:
        # This would normally be async, but simplified for testing
        driver = GraphDatabase.driver(
            server.neo4j_uri,
            auth=(server.neo4j_user, server.neo4j_password)
        )
        
        with driver.session() as session:
            result = session.run("""
                MATCH (n:Chunk) 
                WHERE n.text IS NOT NULL AND n.text <> ''
                AND n.text CONTAINS '„É©„Ç™„Ç¶'
                RETURN n.text as text
                LIMIT 1
            """)
            
            chunks = list(result)
            if chunks:
                print(f"‚úÖ Found {len(chunks)} relevant chunks")
                print(f"Sample: {chunks[0]['text'][:100]}...")
            else:
                print("‚ùå No relevant chunks found")
                
        driver.close()
        
    except Exception as e:
        print(f"‚ùå Query test failed: {e}")

async def main():
    """Main function."""
    if MCP_AVAILABLE:
        server = Neo4jRAGMCPServer()
        await server.run()
    else:
        standalone_test()

if __name__ == "__main__":
    if MCP_AVAILABLE:
        asyncio.run(main())
    else:
        standalone_test()